# ğŸŒ¾ Shetkari Sahayata - Mandi Price Scraper

<div align="center">

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![SeleniumBase](https://img.shields.io/badge/SeleniumBase-UC%20Mode-green.svg)
![GitHub Actions](https://img.shields.io/badge/Automated-GitHub%20Actions-orange.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

**A fully automated, serverless agricultural commodity price scraper and publishing system for Maharashtra farmers.**

[Features](#-features) â€¢ [Architecture](#-architecture) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Automation](#-automated-publishing-pipeline)

</div>

---

## ğŸ“– Overview

This repository serves as the **backend data engine** for the **Shetkari Sahayata** (à¤¶à¥‡à¤¤à¤•à¤°à¥€ à¤¸à¤¹à¤¾à¤¯à¥à¤¯à¤¤à¤¾) Facebook page and Telegram channel. It is a 100% automated, serverless solution designed to:

- ğŸ•·ï¸ **Scrape** daily agricultural commodity prices (Mandi rates) from multiple sources
- ğŸ›¡ï¸ **Bypass** Cloudflare bot-protection using advanced undetected Chrome techniques
- ğŸ’¾ **Store** historical price data in JSON format (GitHub as database)
- ğŸ¤– **Publish** daily market insights to 10,000+ farmers via social media
- ğŸ“Š **Track** price trends across 13 major crops and 40+ markets

The system provides **zero-cost infrastructure** by leveraging GitHub Actions for compute and GitHub repository for storage, while delivering real-time agricultural market intelligence to farming communities.

---

## âœ¨ Features

### ğŸ¯ **Dual-Source Data Collection**
- **Primary Source (MSAMB)**: Rich, detailed data from Maharashtra State Agricultural Marketing Board
  - Min/Max/Modal prices
  - Daily arrivals (quantity)
  - Trade dates
  - Variety information
  - 25+ local Maharashtra markets
  
- **Secondary Source (CommodityOnline)**: National market benchmarks
  - Out-of-state comparative pricing
  - Major markets: Indore, Delhi, Bangalore, Surat, etc.
  - Fallback for crops not tracked by MSAMB

### ğŸŒ¾ **Tracked Commodities**
| Crop | Marathi Name | Key Markets |
|------|--------------|-------------|
| Onion | à¤•à¤¾à¤‚à¤¦à¤¾ | Lasalgaon, Pimpalgaon, Pune |
| Soybean | à¤¸à¥‹à¤¯à¤¾à¤¬à¥€à¤¨ | Latur, Washim, Akola |
| Cotton | à¤•à¤¾à¤ªà¥‚à¤¸ | Hinganghat, Sangamner |
| Maize | à¤®à¤•à¤¾ | Ahmednagar, Pune |
| Wheat | à¤—à¤¹à¥‚ | Pune, Solapur |
| Tur (Arhar) | à¤¤à¥‚à¤° | Latur, Osmanabad |
| Harbara (Chana) | à¤¹à¤°à¤­à¤°à¤¾ | Latur, Ahmednagar |
| Tomato | à¤Ÿà¥‹à¤®à¥…à¤Ÿà¥‹ | Pune, Nashik |
| Pomegranate | à¤¡à¤¾à¤³à¤¿à¤‚à¤¬ | Pune, Solapur |
| Garlic | à¤²à¤¸à¥‚à¤£ | Lasalgaon, Pune |
| Marigold | à¤à¥‡à¤‚à¤¡à¥‚ | Pune, Nashik |
| Rose | à¤—à¥à¤²à¤¾à¤¬ | Pune, Nashik |
| Cocoon | à¤°à¥‡à¤¶à¥€à¤® à¤•à¥‹à¤· | Ramanagara, Kolar |

### ğŸ”§ **Technical Features**
- âœ… Cloudflare bypass using SeleniumBase UC mode
- âœ… Intelligent retry logic and error handling
- âœ… Structured JSON output with metadata
- âœ… Automatic date-based file organization
- âœ… Performance metrics tracking
- âœ… Headless browser execution for CI/CD
- âœ… No external database required (Git as database)

---

## ğŸ—ï¸ Architecture

### **Waterfall Data Pipeline**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA COLLECTION LAYER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  GitHub Actions Cron (5:30 AM & 5:30 PM IST)                            â”‚
â”‚           â”‚                                                               â”‚
â”‚           â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚  â”‚  Python Scraper â”‚                                                     â”‚
â”‚  â”‚  (SeleniumBase) â”‚                                                     â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                                     â”‚
â”‚       â”‚       â”‚                                                           â”‚
â”‚       â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚       â”‚                          â”‚                                       â”‚
â”‚       â–¼                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚    MSAMB    â”‚          â”‚ CommodityOnlineâ”‚                           â”‚
â”‚  â”‚  (Primary)  â”‚          â”‚  (Fallback)    â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚       â”‚                          â”‚                                       â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                  â–¼                                                       â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚         â”‚ Data Processing â”‚                                             â”‚
â”‚         â”‚   & Cleaning    â”‚                                             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚                  â–¼                                                       â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚         â”‚   JSON Output   â”‚                                             â”‚
â”‚         â”‚  with Metadata  â”‚                                             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚                  â–¼                                                       â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚         â”‚  Git Commit &   â”‚                                             â”‚
â”‚         â”‚      Push       â”‚                                             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚                  â–¼                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  â–¼         STORAGE LAYER                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚              GitHub Repository (Database)                                â”‚
â”‚         data/YYYY/MM/crop_prices_YYYY-MM-DD.json                        â”‚
â”‚                                                                           â”‚
â”‚         Public Access: raw.githubusercontent.com                        â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  â–¼      PUBLISHING LAYER                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  Activepieces Workflow (6:45 PM IST)                                    â”‚
â”‚           â”‚                                                               â”‚
â”‚           â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚  â”‚  Fetch JSON     â”‚â”€â”€â”€â”€â”€â”€â–º Wait 5 mins (safeguard)                     â”‚
â”‚  â”‚  (Custom JS)    â”‚                                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚           â”‚                                                               â”‚
â”‚           â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚  â”‚  HTML + CSS     â”‚                                                     â”‚
â”‚  â”‚  Generation     â”‚                                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚           â”‚                                                               â”‚
â”‚           â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚  â”‚   HCTI API      â”‚â”€â”€â”€â”€â”€â”€â–º PNG Infographic                             â”‚
â”‚  â”‚ (Image Render)  â”‚                                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚           â”‚                                                               â”‚
â”‚           â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚  â”‚  Loop: Process  â”‚                                                     â”‚
â”‚  â”‚   Each Crop     â”‚                                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚           â”‚                                                               â”‚
â”‚           â”œâ”€â”€â”€â”€â”€â”€â–º Google Sheets (Historical DB)                        â”‚
â”‚           â”‚                                                               â”‚
â”‚           â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚  â”‚ Google Gemini   â”‚â”€â”€â”€â”€â”€â”€â–º AI-Generated Marathi Post                   â”‚
â”‚  â”‚   2.5 Flash     â”‚                                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚           â”‚                                                               â”‚
â”‚           â”œâ”€â”€â”€â”€â”€â”€â–º Facebook Graph API (Post with Image)                 â”‚
â”‚           â”‚                                                               â”‚
â”‚           â”œâ”€â”€â”€â”€â”€â”€â–º Generate Facebook Deep Link                          â”‚
â”‚           â”‚                                                               â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â–º Telegram Bot API (sendPhoto)                         â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
            10,000+ Farmers
```

### **Data Flow Summary**

1. **Scraping Layer** (Python + SeleniumBase)
   - Fetches HTML from MSAMB and CommodityOnline
   - Parses tables using BeautifulSoup
   - Cleans and normalizes price data
   - Handles pagination and dynamic content

2. **Storage Layer** (GitHub Repository)
   - Stores daily JSON snapshots in `/data/YYYY/MM/` structure
   - Git history provides complete audit trail
   - Public raw.githubusercontent.com URLs for API-like access

3. **Publishing Layer** (Activepieces + APIs)
   - Automated workflow triggered at 6:45 PM IST
   - Transforms JSON into visual infographics
   - AI-generated Marathi social media posts
   - Multi-platform distribution (Facebook + Telegram)

---

## ğŸš€ Installation

### **Prerequisites**
- Python 3.10 or higher
- Git
- Chrome/Chromium browser (for local testing)

### **Local Setup**

#### **Windows**
```powershell
# Clone the repository
git clone https://github.com/yourusername/Mandi-Scraper.git
cd Mandi-Scraper

# Create virtual environment
python -m venv venv
.\venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install ChromeDriver (SeleniumBase will auto-manage)
sbase install chromedriver

# Run the scraper
python scraper.py
```

#### **Linux/macOS**
```bash
# Clone the repository
git clone https://github.com/yourusername/Mandi-Scraper.git
cd Mandi-Scraper

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Install ChromeDriver
sbase install chromedriver

# Run the scraper
python scraper.py
```

---

## ğŸ’» Usage

### **Manual Execution**

Run the scraper manually to fetch today's prices:

```bash
python scraper.py
```

**Output:**
```
ğŸš€ Booting up MSAMB (Primary Engine)...

Processing à¤•à¤¾à¤‚à¤¦à¤¾ from MSAMB...
   âœ… à¤²à¤¾à¤¸à¤²à¤—à¤¾à¤µ: Avg â‚¹2500 | Min â‚¹2200 | Max â‚¹2800 | Date: 19-02-2026
   âœ… à¤ªà¥à¤£à¥‡: Avg â‚¹2600 | Min â‚¹2300 | Max â‚¹2900 | Date: 19-02-2026

ğŸš€ Warming up CommodityOnline (National Fallback)...
   ğŸŒ Checking National Markets for Onion...
      âœ… Indore: â‚¹2400
      âœ… Delhi: â‚¹2700

â±ï¸ Scrape completed in 2m 34s!
ğŸ’¾ Saved to data/2026/02/crop_prices_2026-02-19.json
```

### **Output Format**

The scraper generates a JSON file in the following structure:

```json
{
  "timestamp": "2026-02-19T12:30:45.123456",
  "execution_time_seconds": 154.23,
  "execution_time_formatted": "2m 34s",
  "crops": {
    "onion": {
      "marathi": "à¤•à¤¾à¤‚à¤¦à¤¾",
      "english": "Onion",
      "local": {
        "à¤²à¤¾à¤¸à¤²à¤—à¤¾à¤µ": {
          "modal_price": 2500,
          "min_price": 2200,
          "max_price": 2800,
          "arrival": 15000,
          "variety": "Red",
          "trade_date": "19-02-2026"
        }
      },
      "outstate": {
        "Indore": {
          "modal_price": 2400,
          "variety": "Nasik Red"
        }
      }
    }
  }
}
```

### **Accessing Raw JSON via URL**

Once committed to GitHub, the JSON file is publicly accessible:

```
https://raw.githubusercontent.com/yourusername/Mandi-Scraper/main/data/2026/02/crop_prices_2026-02-19.json
```

This URL is used by the Activepieces workflow to fetch and process data.

---

## ğŸ¤– Automated Publishing Pipeline

### **GitHub Actions Workflow**

The scraper runs automatically twice daily using GitHub Actions:

- **Schedule**: `0 0,12 * * *` (12:00 AM & 12:00 PM UTC = 5:30 AM & 5:30 PM IST)
- **Trigger**: Can also be manually triggered via workflow_dispatch
- **Environment**: Ubuntu-latest with Python 3.10
- **Display**: Uses `xvfb-run` for headless browser execution

**Workflow File**: [`.github/workflows/daily_scrape.yml`](.github/workflows/daily_scrape.yml)

---

## ğŸ¨ Activepieces Publishing Workflow

To ensure farmers receive timely updates without manual intervention, an **Activepieces** automation pipeline runs every evening at **6:45 PM IST**, processing and distributing the scraped data across multiple platforms.

### **ğŸ”„ Flow Architecture & Steps**

#### **Step 1: Start - Run Daily at 6:45 PM**
- **Trigger**: Cron job `45 18 * * *` (6:45 PM IST)
- **Purpose**: Scheduled automation to publish daily market insights

#### **Step 2: Fetch & Format Market Data**
- **Action**: Custom JavaScript code
- **Process**:
  - Fetches today's JSON file directly from `raw.githubusercontent.com` endpoint
  - Maps local Maharashtrian APMC data and out-of-state fallback data
  - Generates structured HTML rows with CSS styling
  - Creates data arrays for downstream processing

#### **Step 3: Wait 5 Minutes (Ensure Data is Fresh)**
- **Action**: Delay safeguard
- **Purpose**: Ensures GitHub Actions has fully committed and deployed the latest JSON file before processing

#### **Step 4: Create Infographic Image**
- **Service**: [HCTI (HTML/CSS to Image) API](https://htmlcsstoimage.com/)
- **Input**: Dynamically generated HTML + CSS
- **Output**: Visually appealing, easily readable market rate infographic (PNG)
- **Features**:
  - Crop-wise prices in tabular format
  - Min/Max/Modal rates with color coding
  - Arrival quantities
  - Trade dates
  - Responsive design optimized for mobile viewing

#### **Step 5: Loop - Process Each Crop**
- **Action**: Array iterator
- **Scope**: Iterates through the structured array of all tracked crops
- **Crops Processed**: Onion, Soybean, Cotton, Maize, Wheat, Tur, Harbara, Tomato, Pomegranate, Garlic, Marigold, Rose, Cocoon

#### **Step 6: Save Crop Rates to Database** (Inside Loop)
- **Service**: Google Sheets API
- **Data Fields Stored**:
  - Date
  - Trade Date
  - Min Price
  - Max Price
  - Average/Modal Price
  - Arrival Quantities
  - Generated Image URL
- **Purpose**: Future trend analysis, farmer queries, historical reports

#### **Step 7: AI - Write Marathi Social Media Post**
- **Service**: Google Gemini 2.5 Flash
- **Prompt Role**: Agricultural market expert
- **Process**:
  - Feeds raw JSON data to Gemini API
  - Uses strict prompt engineering
  - Analyzes day's highest prices and maximum arrivals
  - Writes unique, engaging, emoji-rich summary in natural Marathi
  - Optimized for social media virality and farmer engagement
- **Example Output**:
  ```
  ğŸŒ¾ à¤†à¤œà¤šà¥‡ à¤®à¤‚à¤¡à¥€ à¤­à¤¾à¤µ (19 à¤«à¥‡à¤¬à¥à¤°à¥à¤µà¤¾à¤°à¥€ 2026)
  
  ğŸ§… à¤•à¤¾à¤‚à¤¦à¤¾ - à¤²à¤¾à¤¸à¤²à¤—à¤¾à¤µ à¤®à¤‚à¤¡à¥€à¤¤ à¤¸à¤°à¥à¤µà¤¾à¤§à¤¿à¤• â‚¹2,800/à¤•à¥à¤µà¤¿à¤‚à¤Ÿà¤²! à¤†à¤µà¤• 15 à¤Ÿà¤¨
  ğŸŒ¿ à¤¸à¥‹à¤¯à¤¾à¤¬à¥€à¤¨ - à¤²à¤¾à¤¤à¥‚à¤° à¤¯à¥‡à¤¥à¥‡ â‚¹4,200/à¤•à¥à¤µà¤¿à¤‚à¤Ÿà¤² (à¤‰à¤¤à¥à¤¤à¤® à¤¦à¤°!)
  
  à¤¸à¤‚à¤ªà¥‚à¤°à¥à¤£ à¤®à¤¾à¤¹à¤¿à¤¤à¥€ à¤–à¤¾à¤²à¥€ à¤ªà¤¹à¤¾ ğŸ‘‡
  #MandiRates #à¤¶à¥‡à¤¤à¤•à¤°à¥€à¤¸à¤¹à¤¾à¤¯à¥à¤¯à¤¤à¤¾
  ```

#### **Step 8: Publish Post to Facebook**
- **Service**: Facebook Graph API
- **Platform**: Shetkari Sahayata Facebook Page
- **Content Posted**:
  - HCTI-generated infographic (image attachment)
  - Gemini-generated Marathi caption
  - Automatic hashtags and engagement triggers
- **Result**: Returns unique post ID for tracking

#### **Step 9: Generate Clickable Facebook Link**
- **Action**: Custom JavaScript parser
- **Process**:
  - Parses unique `[PAGE_ID]_[POST_ID]` returned by Facebook API
  - Constructs clean, deep-linked URL
  - Example: `https://www.facebook.com/ShetkariSahayata/posts/123456789`
- **Purpose**: Enable cross-platform sharing and drive organic engagement

#### **Step 10: Send Update to Telegram**
- **Service**: Telegram Bot API (`/sendPhoto`)
- **Platform**: Shetkari Sahayata Telegram Channel
- **Content**:
  - Sends the infographic image
  - Brief, punchy Marathi caption
  - Embeds Facebook deep-link under "Shetkari Sahayata" text (clickable)
- **Purpose**:
  - Cross-platform distribution
  - Drive traffic from Telegram to Facebook
  - Increase organic reach and community engagement
- **Result**: Instant notification delivered to 10,000+ subscribers

---

## ğŸ› ï¸ Technologies Used

### **Scraping & Automation**
| Technology | Purpose |
|------------|---------|
| **[SeleniumBase](https://github.com/seleniumbase/SeleniumBase)** | Undetected Chrome automation, bypasses Cloudflare bot detection |
| **[BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/)** | HTML parsing and data extraction |
| **[GitHub Actions](https://github.com/features/actions)** | Serverless cron job execution (free tier) |
| **Python 3.10+** | Core scripting language |

### **Publishing Pipeline**
| Technology | Purpose |
|------------|---------|
| **[Activepieces](https://www.activepieces.com/)** | Visual workflow automation platform |
| **[HCTI API](https://htmlcsstoimage.com/)** | HTML/CSS to PNG image rendering |
| **[Google Gemini 2.5 Flash](https://deepmind.google/technologies/gemini/)** | Native AI text generation & market analysis |
| **[Google Sheets API](https://developers.google.com/sheets/api)** | Historical data logging and trend analysis |
| **[Facebook Graph API](https://developers.facebook.com/docs/graph-api)** | Automated social media posting |
| **[Telegram Bot API](https://core.telegram.org/bots/api)** | Cross-platform message distribution |

### **Infrastructure**
| Component | Purpose |
|-----------|---------|
| **GitHub Repository** | Version control + storage (database) |
| **Ubuntu (GitHub Runners)** | Execution environment for scraper |
| **Xvfb (Virtual Display)** | Headless browser automation |
| **raw.githubusercontent.com** | Public JSON API endpoint |

---

## ğŸ“‚ Project Structure

```
Mandi-Scraper/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ daily_scrape.yml       # GitHub Actions automation config
â”œâ”€â”€ data/
â”‚   â””â”€â”€ YYYY/                      # Year-based organization
â”‚       â””â”€â”€ MM/                    # Month-based organization
â”‚           â””â”€â”€ crop_prices_YYYY-MM-DD.json  # Daily price snapshots
â”œâ”€â”€ downloaded_files/              # Temporary browser downloads (ignored)
â”œâ”€â”€ venv/                          # Python virtual environment (ignored)
â”œâ”€â”€ .gitignore                     # Ignored files (venv, __pycache__, etc.)
â”œâ”€â”€ README.md                      # This comprehensive documentation
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ scraper.py                     # Main scraper script (200 lines)
```

---

## ğŸ“Š Data Coverage

### **Maharashtra Markets (27)**
à¤…à¤¹à¤¿à¤²à¥à¤¯à¤¾à¤¨à¤—à¤° (Ahmednagar), à¤°à¤¾à¤¹à¤¤à¤¾ (Rahata), à¤°à¤¾à¤¹à¥à¤°à¥€ (Rahuri), à¤†à¤³à¥‡à¤«à¤¾à¤Ÿà¤¾ (Alephata), à¤¸à¤‚à¤—à¤®à¤¨à¥‡à¤° (Sangamner), à¤²à¤¾à¤¸à¤²à¤—à¤¾à¤µ (Lasalgaon), à¤ªà¥à¤£à¥‡ (Pune), à¤¸à¥‹à¤²à¤¾à¤ªà¥‚à¤° (Solapur), à¤¨à¤¾à¤—à¤ªà¥‚à¤° (Nagpur), à¤®à¥à¤‚à¤¬à¤ˆ (Mumbai), à¤²à¤¾à¤¤à¥‚à¤° (Latur), à¤…à¤•à¥‹à¤²à¤¾ (Akola), à¤…à¤®à¤°à¤¾à¤µà¤¤à¥€ (Amravati), à¤µà¤¾à¤¶à¤¿à¤® (Washim), à¤¹à¤¿à¤‚à¤—à¤£à¤˜à¤¾à¤Ÿ (Hinganghat), à¤¯à¤µà¤¤à¤®à¤¾à¤³ (Yavatmal), à¤œà¤³à¤—à¤¾à¤µ (Jalgaon), à¤œà¤¾à¤²à¤¨à¤¾ (Jalna), à¤ªà¤¿à¤‚à¤ªà¤³à¤—à¤¾à¤µ (Pimpalgaon), à¤¨à¤¾à¤°à¤¾à¤¯à¤£à¤—à¤¾à¤µ (Narayangaon), à¤¸à¤¾à¤‚à¤—à¥‹à¤²à¤¾ (Sangola), à¤ªà¤‚à¤¢à¤°à¤ªà¥‚à¤° (Pandharpur), à¤¸à¤Ÿà¤¾à¤£à¤¾ (Satana), à¤¬à¤¾à¤°à¤¾à¤®à¤¤à¥€ (Baramati), à¤¤à¤³à¥‡à¤—à¤¾à¤µ (Talegaon), à¤¸à¤¾à¤¤à¤¾à¤°à¤¾ (Satara), à¤•à¤²à¥à¤¯à¤¾à¤£ (Kalyan)

### **Out-of-State Markets (17)**
Indore (MP), Delhi, Bangalore (KA), Surat (GJ), Rajkot (GJ), Ujjain (MP), Neemuch (MP), Mandsaur (MP), Bhopal (MP), Kadi (GJ), Dahod (GJ), Gulbarga (KA), Kolar (KA), Ramanagara (KA), Davangere (KA), Kanpur (UP), Nizamabad (TG)

---

## ğŸ” How It Works

### **Scraping Logic**

#### **Part 1: MSAMB (Primary Source)**
1. Opens MSAMB website using undetected Chrome
2. For each crop, selects commodity from dropdown
3. Waits for dynamic table to render
4. Parses table rows to extract:
   - Market name (Marathi)
   - Trade date
   - Variety
   - Min/Max/Average prices
   - Arrival quantity (in quintals)
5. Filters for target Maharashtra markets
6. Stores rich, detailed local market data

#### **Part 2: CommodityOnline (Fallback Source)**
1. Opens CommodityOnline national portal
2. Bypasses Cloudflare with 6-second delay
3. For each crop, navigates to dedicated price page
4. Scrapes national market table
5. Filters out Maharashtra markets (to avoid duplicates)
6. Extracts modal prices for out-of-state markets
7. Provides comparative pricing context

#### **Part 3: Data Processing & Storage**
1. Merges local and out-of-state data
2. Adds metadata (timestamp, execution time)
3. Organizes by year/month folder structure
4. Saves as pretty-printed JSON with UTF-8 encoding
5. Git commits and pushes to repository
6. Makes data publicly accessible via raw.githubusercontent.com

---

## ğŸ¤ Contributing

Contributions are welcome! Here are some ways you can help:

- ğŸ› **Report bugs**: Create an issue with detailed reproduction steps
- ğŸ’¡ **Suggest features**: Propose new markets, crops, or data sources
- ğŸ”§ **Submit PRs**: Code improvements, bug fixes, documentation
- ğŸ“– **Improve docs**: Fix typos, add examples, translate content
- ğŸŒ **Localization**: Add support for more regional languages

### **Development Workflow**

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature-name`
3. Make your changes with clear commit messages
4. Test locally: `python scraper.py`
5. Ensure no errors: Check JSON output validity
6. Commit: `git commit -m "Add: your feature description"`
7. Push: `git push origin feature/your-feature-name`
8. Create a Pull Request with detailed description

### **Code Style Guidelines**
- Follow PEP 8 for Python code
- Add comments for complex logic
- Update README.md if adding new features
- Test with both sources (MSAMB & CommodityOnline)

---

## ğŸ› Troubleshooting

### **Common Issues**

**Issue: Cloudflare blocks scraper**
```
Solution: Ensure SeleniumBase UC mode is enabled
- Check: sb = SB(uc=True, test=True, headless=True)
- Update: pip install --upgrade seleniumbase
```

**Issue: ChromeDriver not found**
```
Solution: Reinstall ChromeDriver
- Command: sbase install chromedriver
```

**Issue: Incomplete data in JSON**
```
Solution: Increase wait times for dynamic content
- Adjust sleep values in scraper.py (sb.sleep())
- Check network speed and website responsiveness
```

**Issue: GitHub Actions fails**
```
Solution: Check workflow logs
- Verify xvfb-run is working
- Ensure requirements.txt is up-to-date
- Check GitHub Actions quota limits
```

---

## ğŸ“ License

This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.

### **MIT License Summary**
- âœ… Commercial use
- âœ… Modification
- âœ… Distribution
- âœ… Private use
- âŒ Liability
- âŒ Warranty

---

## ğŸ™ Acknowledgments

- **MSAMB**: Maharashtra State Agricultural Marketing Board for providing public market data
- **CommodityOnline**: National commodity price aggregation
- **Farmers of Maharashtra**: The inspiration and primary beneficiaries of this project
- **Shetkari Sahayata Community**: 10,000+ followers on Facebook and Telegram who rely on accurate market information
- **Open Source Community**: SeleniumBase, BeautifulSoup, and Python ecosystem contributors

---

## ğŸ“ Contact & Support

### **Social Media**
- ğŸ“˜ **Facebook**: [Shetkari Sahayata Page](https://www.facebook.com/ShetkariSahayata)
- ğŸ“± **Telegram**: [@ShetkariSahayata](https://t.me/ShetkariSahayata)

### **Technical Support**
- ğŸ› **Bug Reports**: [GitHub Issues](https://github.com/yourusername/Mandi-Scraper/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/yourusername/Mandi-Scraper/discussions)
- ğŸ“§ **Email**: contact@shetkari-sahayata.com

### **Documentation**
- ğŸ“– **Wiki**: [GitHub Wiki](https://github.com/yourusername/Mandi-Scraper/wiki)
- ğŸ¥ **Video Tutorial**: Coming soon
- ğŸ“„ **API Docs**: Access raw JSON via GitHub raw URLs

---

## ğŸ“ˆ Project Stats

- **Total Crops Tracked**: 13
- **Total Markets Covered**: 44 (27 MH + 17 Out-of-state)
- **Daily Executions**: 2 times (5:30 AM & 5:30 PM IST)
- **Data Points per Day**: ~200+ price records
- **Storage Cost**: $0 (GitHub repository)
- **Compute Cost**: $0 (GitHub Actions free tier)
- **Community Reach**: 10,000+ farmers
- **Languages**: Python, JavaScript (Activepieces), Marathi (Output)

---

## ğŸ—ºï¸ Roadmap

### **Planned Features**
- [ ] SMS alerts for price spikes/drops
- [ ] WhatsApp integration via Business API
- [ ] Historical price trend charts
- [ ] Price prediction using ML models
- [ ] Mobile app (React Native)
- [ ] Multi-language support (Hindi, Kannada, Gujarati)
- [ ] Weather data integration
- [ ] Crop advisory based on market trends

### **In Progress**
- [x] GitHub Actions automation
- [x] Activepieces publishing pipeline
- [x] Comprehensive documentation

### **Completed**
- [x] Dual-source scraping (MSAMB + CommodityOnline)
- [x] Cloudflare bypass
- [x] JSON data storage
- [x] Facebook + Telegram publishing
- [x] AI-generated Marathi posts

---

## â­ Star History

If this project helps you or your community, please consider giving it a â­ on GitHub!

---

<div align="center">

**Made with â¤ï¸ for Maharashtra Farmers**

*Empowering 10,000+ farmers with real-time market intelligence*

---

**"à¤•à¥ƒà¤·à¥€ à¤¹à¤¾ à¤…à¤°à¥à¤¥à¤µà¥à¤¯à¤µà¤¸à¥à¤¥à¥‡à¤šà¤¾ à¤•à¤£à¤¾ à¤†à¤¹à¥‡"**  
*"Agriculture is the backbone of the economy"*

---

Â© 2026 Shetkari Sahayata | [Privacy Policy](#) | [Terms of Service](#)

</div>
